{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf676cc-73bb-4362-8155-9b7347aa5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"DataLak\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f818585-19ab-4580-8319-66e71a4dc8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"file:///home/jovyan/work/data/raw/employee-data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf71a71f-a7e4-4749-a8e5-0793dd9c2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+------+----------+--------+\n",
      "|      date|      name| id|salary|department|trim_col|\n",
      "+----------+----------+---+------+----------+--------+\n",
      "|2023-01-01|  John Doe|101| 50000|        HR|   abc  |\n",
      "|2023-01-01|  John Doe|101| 50000|        HR|   abc  |\n",
      "|2023-02-01|Jane Smith|102| 60000|        IT|      NA|\n",
      "+----------+----------+---+------+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f5b897-a617-41ec-af7b-306ac0332e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- trim_col: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0918e5fe-fada-4017-a3cc-496fcec66695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, id: string, salary: string, department: string, trim_col: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4949484-e661-43f9-beb4-855881fa3217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff3e6fc-b8ba-4531-80b5-bc60e76099e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date=datetime.date(2023, 1, 1), name='John Doe', id=101, salary=50000, department='HR', trim_col='  abc  '),\n",
       " Row(date=datetime.date(2023, 1, 1), name='John Doe', id=101, salary=50000, department='HR', trim_col='  abc  ')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "132ad6c0-3b9f-4e48-911c-584880518809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf92c8-591f-4371-947d-fe2d557401e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "department,bonus\n",
    "HR,5000\n",
    "IT,7000\n",
    "Finance,6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "931bf88f-0a9f-4cb6-92d8-3df317f7bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bonus=spark.read.csv(\"file:///home/jovyan/work/data/raw/dept_bonus.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82884985-2423-4805-bf65-2ed35355cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|bonus|\n",
      "+----------+-----+\n",
      "|        HR| 5000|\n",
      "+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bonus.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a151832-8d55-466f-b244-c13a5bdcb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.join(df_bonus,\"department\",\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4369fbe2-06e0-4e12-a6e0-c67ce34fbdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---+------+--------+-----+\n",
      "|department|      date|      name| id|salary|trim_col|bonus|\n",
      "+----------+----------+----------+---+------+--------+-----+\n",
      "|        HR|2023-01-01|  John Doe|101| 50000|   abc  | 5000|\n",
      "|        HR|2023-01-01|  John Doe|101| 50000|   abc  | 5000|\n",
      "|        IT|2023-02-01|Jane Smith|102| 60000|      NA| 7000|\n",
      "+----------+----------+----------+---+------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3e32a00-42ec-4ac4-acef-880cdf42f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- department: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- trim_col: string (nullable = true)\n",
      " |-- bonus: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c149942-d420-4864-9a87-16a95953cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5bb11cd4-906c-4547-9767-43a56252208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+---+------+--------+-----+\n",
      "|department|      date|     name| id|salary|trim_col|bonus|\n",
      "+----------+----------+---------+---+------+--------+-----+\n",
      "|        IT|2024-05-01| Lisa Ray|110| 68000|     jkl| NULL|\n",
      "|        HR|2024-06-01|Sam Green|111| 55000|      NA| NULL|\n",
      "+----------+----------+---------+---+------+--------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+----------+----------+---+------+--------+-----+\n",
      "|department|      date|      name| id|salary|trim_col|bonus|\n",
      "+----------+----------+----------+---+------+--------+-----+\n",
      "|        HR|2023-01-01|  John Doe|101| 50000|   abc  | 5000|\n",
      "|        HR|2023-01-01|  John Doe|101| 50000|   abc  | 5000|\n",
      "|        IT|2023-02-01|Jane Smith|102| 60000|      NA| 7000|\n",
      "+----------+----------+----------+---+------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_data = [\n",
    "    (\"IT\",\"2024-05-01\", \"Lisa Ray\", 110, 68000, \"jkl\"),\n",
    "    (\"HR\",\"2024-06-01\", \"Sam Green\", 111, 55000, \"NA\"),\n",
    "    (\"Sales\",\"2024-07-01\", \"Kate White\", 112, 71000, \"mno\"),\n",
    "    ( \"Finance\",\"2024-08-01\", \"Paul Black\", 113, 62000, \"abc\")\n",
    "]\n",
    "columns = [\"department\",\"date\", \"name\", \"id\", \"salary\", \"trim_col\"]\n",
    "df_addData=spark.createDataFrame(add_data,columns)\n",
    "\n",
    "\n",
    "\n",
    "# Add missing 'bonus' column with default value (e.g. 0 or None)\n",
    "df_addData_with_bonus=df_addData.withColumn(\"bonus\",lit(None).cast(\"int\"))\n",
    "df_addData_with_bonus.show(2)\n",
    "\n",
    "\n",
    "new_new_df=new_df.unionByName(df_addData_with_bonus)\n",
    "new_new_df.show(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8128c13c-2e2e-4857-b0d5-f48d49f38d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---+------+--------+-----+\n",
      "|department|      date|      name| id|salary|trim_col|bonus|\n",
      "+----------+----------+----------+---+------+--------+-----+\n",
      "|        HR|2023-01-01|  John Doe|101| 50000|   abc  | 5000|\n",
      "|        HR|2023-01-01|  John Doe|101| 50000|   abc  | 5000|\n",
      "|        IT|2023-02-01|Jane Smith|102| 60000|      NA| 7000|\n",
      "+----------+----------+----------+---+------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_new_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c92b58a-79b7-4e28-8d54-99bf859ae90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,sum,avg, trim, upper, when, to_date,coalesce, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b32d41d9-0ac7-4418-9e1f-d41370cc3b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      avg(salary)|\n",
      "+-----------------+\n",
      "|60428.57142857143|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_salary=new_new_df.agg(avg(col(\"salary\"))).alias(\"mean_salary\")\n",
    "mean_salary.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e026cc8-6918-4769-b7df-454859e7a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_salary=mean_salary.collect()[0][\"avg(salary)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01b8ee-44f1-48cd-841f-62f75e49e9e2",
   "metadata": {},
   "source": [
    "collect turn to list of row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a02d5ebb-68e1-474c-9dbd-d5596a4f3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cleaned=(new_new_df.dropna().dropDuplicates(). withColumn(\"trim_col\",trim(col(\"trim_col\")))\n",
    "                 .withColumn(\"salary\",col(\"salary\").cast(\"int\"))\n",
    "                  .withColumn(\"name\",upper(col(\"name\")))\n",
    "                   .withColumn(\"future_salary\",col(\"salary\")*10)\n",
    "                    .withColumn(\"trim_col\",when(col(\"trim_col\")==\"NA\",None).otherwise(col(\"trim_col\")))\n",
    "                    .withColumnRenamed(\"trim_col\",\"trim\")\n",
    "                     .withColumn(\"date\",to_date(col(\"date\"),\"yyy-MM-dd\"))\n",
    "                      .drop(\"id\")\n",
    "                       .withColumn(\"salary\",when(col(\"salary\")<0,None).otherwise(col(\"salary\")))\n",
    "                        .withColumn(\"salary\",coalesce(col(\"salary\"),lit(mean_salary)))\n",
    "           )\n",
    "                    \n",
    "\n",
    "                    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "800872ad-121a-485b-8dd2-198b1a0b4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-------+----+-----+-------------+\n",
      "|department|      date|      name| salary|trim|bonus|future_salary|\n",
      "+----------+----------+----------+-------+----+-----+-------------+\n",
      "|        HR|2023-01-01|  JOHN DOE|50000.0| abc| 5000|       500000|\n",
      "|        IT|2023-02-01|JANE SMITH|60000.0|NULL| 7000|       600000|\n",
      "+----------+----------+----------+-------+----+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_cleaned.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bda66ea4-7a1b-4cff-98c5-34c8ee7abc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg=(df_cleaned.filter(col(\"salary\")>60000)\n",
    "        .groupBy(\"department\").agg(avg(\"salary\"))\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6dde0b1a-8283-40e2-9c3b-db481e9d6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|department|avg(salary)|\n",
      "+----------+-----------+\n",
      "|        HR|    72000.0|\n",
      "|   Finance|    65000.0|\n",
      "|        IT|    70000.0|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "01f1e621-12e7-4645-9b6c-1cebd8e7c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 48026)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_agg.write.mode(\"overwrite\").partitionBy(\"department\").parquet(\"file:///home/jovyan/work/data/processed/employee_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e8d8c-c4ee-4382-b98f-54529f26f83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58dc81-ce2e-4ff8-a1d7-b581c8e609bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
